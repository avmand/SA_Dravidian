
"""

Citation:
@inproceedings{ bitsnlp2021dravidian,
 title={Sentiment Analysis of Dravidian Code Mixed Data},
 author={Mandalam, Asrita Venkata and Sharma, Yashvardhan},
 booktitle={ 15th Conference of the European Chapter of the Association for Computational Linguistics 2021 (EACL 2021) },
 year={2021}
}  

"""


import pandas as pd
import re
from sklearn.metrics import classification_report, accuracy_score, f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer

def token(sentence):
    tokens = []
    for t in re.findall("[a-zA-Z]+",sentence):
         if len(t)>=1:
             tokens.append(t)
    return tokens

def emoji_ch (words):
    if words == 'üòÑ' :
      words='good'
    elif words == 'üòÜ' :
      words='good'
    elif words == 'üòä' :
      words='good'
    elif words == 'üòÉ' :
      words='good'	
    elif words == 'ü§¨' :
      words='bad'
    elif words == 'üòè' :
      words='good'	
    elif words == 'üòç' :
      words='good'	
    elif words == 'üòò' :
      words='good'
    elif words == 'üòö' :
      words='good'	
    elif words == 'üò≥' :
      words='flushed'	
    elif words == 'üòå' :
      words='bad'
    elif words == 'üòÜ' :
      words='good'	
    elif words == 'üòÇ' :
      words='good'	
    elif words == 'üòé' :
      words='good'		
    elif words == 'ü§Ø' :
      words='blow_mind'	
    elif words == '‚úåÔ∏è' :
      words='vhand'			
    elif words == 'ü§ò' :
      words='metal'
    elif words == 'ü§¶' :
      words='bad'				
    elif words == 'ü§©':
      words='good'
    elif words == 'ü•∞':
      words='good'
    elif words == 'ü§î':
      words='thinking'
    elif words == 'ü§£':
      words='good'
    elif words == 'ü§ó':
      words = 'good'
    else :
      return None
    return words+" "


def tamilchar(ch):
    if ch == u'\u0B85' or ch== u'‡ÆÖ':
        ch="A"
    elif ch == u'\u0B86' or ch== u'‡ÆÜ':
        ch="AA"
    elif ch == u'\u0B87' or ch== u'‡Æá':
        ch="I"
    elif ch == u'\u0B88' or ch== u'‡Æà':
        ch="II"
    elif ch == u'\u0B89' or ch== u'‡Æâ':
        ch="U"
    elif ch == u'\u0B8A' or ch== u'‡Æä':
        ch="UU"
    elif ch == u'\u0B8E' or ch== u'‡Æé':
        ch="E"
    elif ch == u'\u0B8F' or ch== u'‡Æè':
        ch="EE"
    elif ch == u'\u0B90' or ch== u'‡Æê':
        ch="AI"
    elif ch == u'\u0B92' or ch== u'‡Æí':
        ch="O"
    elif ch == u'\u0B93' or ch== u'‡Æì':
        ch="OO"
    elif ch == u'\u0B94' or ch== u'‡Æî':
        ch="AU"
    elif ch ==u'\u0B95'or ch==u'‡Æï':
        ch="KA"
    elif ch ==u'\u0B99'or ch==u'‡Æô':
        ch="NGA"
    elif ch ==u'\u0B9A'or ch==u'‡Æö':
        ch="SA"
    elif ch ==u'\u0B9C' or ch==u'‡Æú':
        ch="JA"
    elif ch ==u'\u0B9E'or ch==u'‡Æû':
        ch=u"NYA"
    elif ch ==u'\u0B9F'or ch==u'‡Æü':
        ch="DA"
    elif ch ==u'\u0BA3'or ch==u'‡Æ£':
        ch="NNA"
    elif ch ==u'\u0BA4'or ch==u'‡Æ§':
        ch="THA"
    elif ch ==u'\u0BA8'or ch==u'‡Æ®':
        ch="NA"
    elif ch ==u'\u0BA9' or ch==u'‡Æ©':
        ch="NA"
    elif ch ==u'\u0BAA'or ch==u'‡Æ™':
        ch="PA"
    elif ch ==u'\u0BAE'or ch==u'‡ÆÆ':
        ch="MA"
    elif ch ==u'\u0BAF' or ch==u'‡ÆØ':
        ch="YA"
    elif ch ==u'\u0BB0' or ch==u'‡Æ∞':
        ch="RA"
    elif ch ==u'\u0BB1'or ch==u'‡Æ±':
        ch="RRA"
    elif ch ==u'\u0BB2' or ch==u'‡Æ≤':
        ch="LA"
    elif ch ==u'\u0BB3'or ch==u'‡Æ≥':
        ch="LLA"
    elif ch ==u'\u0BB4'or ch ==u'‡Æ¥':
        ch=="LLLA"
    elif ch ==u'\u0BB5'or ch==u'‡Æµ':
        ch="VA"
    elif ch ==u'\u0BB6'or ch==u'‡Æ∂':
        ch="SHA"
    elif ch ==u'\u0BB7'or ch==u'‡Æ∑':
        ch="SSA"
    elif ch ==u'\u0BB8'or ch==u'‡Æ∏':
        ch="SA"
    elif ch ==u'\u0BB9'or ch==u'‡Æπ':
        ch="HA"
    elif ch ==u'\u0BBE'or ch==u'$‡Ææ':
        ch="AA"
    elif ch ==u'\u0BBF'or ch==u'$‡Æø':
        ch="I"
    elif ch ==u'\u0BC0'or ch==u'$‡ØÄ':
        ch="II"
    elif ch ==u'\u0BC1'or ch==u'$‡ØÅ':
        ch="U"
    elif ch ==u'\u0BC2'or ch==u'‡ØÇ$':
        ch="UU"
    elif ch ==u'\u0BC6'or ch==u'$‡ØÜ':
        ch="E"
    elif ch ==u'\u0BC7'or ch==u'$‡Øá':
        ch="EE"
    elif ch ==u'\u0BC8'or ch==u'$‡Øà':
        ch="AI"
    elif ch ==u'\u0BCA'or ch==u'$‡Øä':
        ch="O"
    elif ch ==u'\u0BCB'or ch==u'$‡Øã':
        ch="OO"
    elif ch ==u'\u0BCC'or ch==u'$‡Øå':
        ch="AU"
    elif ch ==u'\u0BCD'or ch==u'$‡Øç':
        ch="PULLI"
    elif ch ==u'\u0BD0'or ch==u'‡Øê':
        ch="OM"
    elif ch ==u'\u0BD7'or ch==u'$‡Øó':
        ch="AU"       
    else:
        return None
    return ch

def preprocess(word):
  word=re.sub(r'([a-z])\1+$', r'\1',word)
  return word

def tamilword(word):
    fla=0
    string=""
    for ch in word:
        if(tamilchar(ch) is not None):
            ch=tamilchar(ch)
            fla=1
        if(emoji_ch(ch) is not None):
            ch=emoji_ch(ch)
            fla=1
        string=string+str(ch)
    if(fla==1):
        return string
    else:
        return None

labels = ['Mixed_feelings ','Negative ','Positive ','not-Tamil ','unknown_state '] 
train_csv='/content/drive/My Drive/Dravidian/EACL/tamil_train.tsv'



colnames=['tweet','sentiment']
dataset_csv = pd.read_csv(train_csv,names=colnames, delimiter='\t', error_bad_lines=False, header=None,
                      usecols=colnames, na_values=" NaN",encoding="ISO-8859-1")

dataset_csv = dataset_csv.dropna()

dataset=dataset_csv
dataset=dataset[1:]

for index, line in dataset.iterrows():
  if line['sentiment'].lower() == labels[0].lower():
        line['sentiment'] = "0"
  elif line['sentiment'].lower() == labels[1].lower():
        line['sentiment'] = "1"
  elif line['sentiment'].lower() == labels[2].lower():
        line['sentiment'] = "2"
  elif line['sentiment'].lower() == labels[3].lower():
        line['sentiment'] = "3"
  elif line['sentiment'].lower() == labels[4].lower():
        line['sentiment'] = "4"
  i=line[0].split()
  for word in range(len(i)):
      for ch in range(len(i[word])):
          checker=emoji_ch(i[word][ch])
          if(checker is not None):
              i[word]+=checker
      
      checker=tamilword(i[word])
      if(checker is not None):
          i[word]=checker
      i[word]=preprocess(i[word])



x_train = dataset['tweet']
y_train = dataset['sentiment']

test_csv='/content/drive/My Drive/Dravidian/EACL/tamil_dev.tsv'

labels = ['Mixed_feelings','Negative','Positive','not-Tamil','unknown_state'] 
colnames=['index','tweet','sentiment']
dataset_csv = pd.read_csv(r'/content/drive/My Drive/Dravidian/EACL/tamil_test.tsv',names=colnames, delimiter='\t', error_bad_lines=False, header=None,
                      usecols=['tweet','sentiment'], na_values=" NaN",skiprows=[0])

dataset_csv = dataset_csv.dropna()

dataset=dataset_csv
dataset=dataset[1:]

for index, line in dataset.iterrows():
  if line['sentiment'].lower() == labels[0].lower():
        line['sentiment'] = "0"
  elif line['sentiment'].lower() == labels[1].lower():
        line['sentiment'] = "1"
  elif line['sentiment'].lower() == labels[2].lower():
        line['sentiment'] = "2"
  elif line['sentiment'].lower() == labels[3].lower():
        line['sentiment'] = "3"
  elif line['sentiment'].lower() == labels[4].lower():
        line['sentiment'] = "4"
  i=line[0].split()
  for word in range(len(i)):
      for ch in range(len(i[word])):
          checker=emoji_ch(i[word][ch])
          if(checker is not None):
              i[word]+=checker
      
      checker=tamilword(i[word])
      if(checker is not None):
          i[word]=checker
      i[word]=preprocess(i[word])


x_test = dataset['tweet']
y_test = dataset['sentiment']

def malchar(ch):
    if ch == u'‡¥Ö':
        ch="A"
    elif ch == u'‡¥Ü':
        ch="AA"
    elif ch == u'‡¥á':
        ch="I"
    elif ch == u'‡¥à':
        ch="II"
    elif ch == u'‡¥â':
        ch="U"
    elif ch == u'‡¥ä':
        ch="UU"
    elif ch == u'‡¥é':
        ch="E"
    elif ch == u'‡¥è':
        ch="EE"
    elif ch == u'‡¥ê':
        ch="AI"
    elif ch == u'‡¥í':
        ch="O"
    elif ch == u'‡¥ì':
        ch="OO"
    elif ch == u'‡¥î':
        ch="AU"
    elif ch ==u'‡¥ï'or ch==u'‡¥ñ':
        ch="KA"
    elif ch ==u'‡¥ó'or ch==u'‡¥ò':
        ch="GA"
    elif ch ==u'‡¥ô':
        ch="NGA"
    elif ch ==u'‡¥ö'or ch==u'‡¥õ':
        ch="CH" 
    elif ch ==u'‡¥ö'or ch==u'‡¥õ':
        ch="CH" 
    elif ch ==u'‡¥∂'or ch==u'‡¥∑':
        ch="SH"
    elif ch ==u'‡¥∏':
        ch="S"
    elif ch ==u'‡¥ú' or ch==u'‡¥ù':
        ch="JA"
    elif ch ==u'‡¥°'or ch==u'‡¥¶':
        ch="DA"
    elif ch ==u'‡¥•'or ch==u'‡¥§':
        ch="THA"
    elif ch ==u'‡¥£'or ch==u'‡¥®':
        ch="NA"
    elif ch ==u'‡¥™':
        ch="PA"
    elif ch ==u'‡¥Æ':
        ch="MA"
    elif ch ==u'‡¥Ø':
        ch="YA"
    elif ch ==u'‡¥∞':
        ch="RA"
    elif ch ==u'‡¥≥':
        ch="LA"
    elif ch ==u'‡¥µ':
        ch="VA"
    elif ch ==u'‡¥π':
        ch="HA"
    elif ch ==u'‡¥≠'or ch==u'‡¥¨':
        ch="BA"
    elif ch ==u'‡¥¢'or ch==u'‡¥ß':
        ch="DH"
    elif ch ==u'‡¥†':
        ch="DT"
    elif ch ==u'‡¥ü':
        ch="T"
    elif ch ==u'‡¥û':
        ch="NJ"
    elif ch ==u'‡¥´':
        ch="PH"
    elif ch ==u'‡¥¥':
        ch="ZH"
    elif ch ==u'‡¥±':
        ch="RA"    
    else:
        return None
    return ch


def malword(word):
    fla=0
    string=""
    for ch in word:
        if(malchar(ch) is not None):
            ch=malchar(ch)
            fla=1
        string=string+str(ch)
    if(fla==1):
        return string
    else:
        return None


colnames=['text','label']
df = pd.read_csv(r'/content/drive/MyDrive/Dravidian/EACL/malayalam_train.tsv',names=colnames, delimiter='\t', error_bad_lines=False, header=None,
                      usecols=['text','label'], na_values=" NaN",skiprows=[0])


df_val = pd.read_csv(r'/content/drive/MyDrive/Dravidian/EACL/malayalam_dev.tsv',names=colnames, delimiter='\t', error_bad_lines=False, header=None,
                      usecols=['text','label'], na_values=" NaN",skiprows=[0])

colnames=['index','text','label']
df_test = pd.read_csv(r'/content/drive/MyDrive/Dravidian/EACL/malayalam_test.tsv',names=colnames, delimiter='\t', error_bad_lines=False, header=None,
                      usecols=['text','label'], na_values=" NaN",skiprows=[0])

labels = ['Mixed_feelings ','Negative ','Positive ','not-malayalam ','unknown_state '] 

for index, line in df.iterrows():
  if line['label'].lower() == labels[0].lower():
        line['label'] = "0"
  elif line['label'].lower() == labels[1].lower():
        line['label'] = "1"
  elif line['label'].lower() == labels[2].lower():
        line['label'] = "2"
  elif line['label'].lower() == labels[3].lower():
        line['label'] = "3"
  elif line['label'].lower() == labels[4].lower():
        line['label'] = "4"
  i=line[0].split()
  for word in range(len(i)):
      for ch in range(len(i[word])):
          checker=emoji_ch(i[word][ch])
          if(checker is not None):
              i[word]+=checker
      
      checker=malword(i[word])
      if(checker is not None):
          i[word]=checker
      i[word]=preprocess(i[word])
          
          
  line[0]=' '.join(i)

for index, line in df_val.iterrows():
  if line['label'].lower() == labels[0].lower():
        line['label'] = "0"
  elif line['label'].lower() == labels[1].lower():
        line['label'] = "1"
  elif line['label'].lower() == labels[2].lower():
        line['label'] = "2"
  elif line['label'].lower() == labels[3].lower():
        line['label'] = "3"
  elif line['label'].lower() == labels[4].lower():
        line['label'] = "4"
  i=line[0].split()
  for word in range(len(i)):
      for ch in range(len(i[word])):
          checker=emoji_ch(i[word][ch])
          if(checker is not None):
              i[word]+=checker
      
      checker=malword(i[word])
      if(checker is not None):
          i[word]=checker
      i[word]=preprocess(i[word])
          
          
  line[0]=' '.join(i)


labels = ['Mixed_feelings','Negative','Positive','not-malayalam','unknown_state'] 
for index, line in df_test.iterrows():
  if line['label'].lower() == labels[0].lower():
        line['label'] = "0"
  elif line['label'].lower() == labels[1].lower():
        line['label'] = "1"
  elif line['label'].lower() == labels[2].lower():
        line['label'] = "2"
  elif line['label'].lower() == labels[3].lower():
        line['label'] = "3"
  elif line['label'].lower() == labels[4].lower():
        line['label'] = "4"
  i=line[0].split()
  for word in range(len(i)):
      for ch in range(len(i[word])):
          checker=emoji_ch(i[word][ch])
          if(checker is not None):
              i[word]+=checker
      i[word]=preprocess(i[word])
      
      checker=malword(i[word])
      if(checker is not None):
          i[word]=checker
      i[word]=preprocess(i[word])
          
          
  line[0]=' '.join(i)

print(df.head())
print(df_val.head())
print(df_test.head())

x_train = df['text']
y_train = df['label']
x_dev = df_val['text']
y_dev = df_val['label']
x_test = df_test['text']
y_test = df_test['label']

vectorizer = TfidfVectorizer(max_features=5000, sublinear_tf=True, ngram_range=(1,2))
X_train = vectorizer.fit_transform(x_train).toarray()
X_test = vectorizer.transform(x_test).toarray()

print(y_train, y_test)

att = [5,12] #temp
for i in range(len(att)):
    names = ["SVM Linear", "Logistic Regression" ]
    classifiers = [
        LinearSVC(random_state=0, tol=1e-6, multi_class= 'crammer_singer',dual = True, intercept_scaling = att[i]) ,
        LogisticRegression(max_iter=500, solver = 'newton-cg',C = att[i], multi_class = 'ovr')
    ]

    models = zip(names, classifiers)
    results = []
    names = []
    print("att: ",att[i])
    for name, model in models:
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        print(name)
        print("Acc: ", accuracy_score(y_test, predictions) , f1_score(y_test, predictions, average="weighted"))
        print(classification_report(y_test, predictions))

